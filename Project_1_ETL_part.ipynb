{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL process by using Python:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## • 1. Extract\n",
    "### 1(1). Extract the csv files that I'm going to use, and transform them into dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_olympic_medals = pd.read_csv(\"olympic_medals.csv\")\n",
    "df_continent = pd.read_csv(\"list-of-countries_areas-by-continent-2024.csv\")\n",
    "df_olympic_hosts = pd.read_csv(\"olympic_hosts.csv\")\n",
    "df_mental_illness = pd.read_csv(\"mental-illness.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1(2). Check the columns that contain null values for the above four dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "participant_title    15113\n",
      "athlete_url           4670\n",
      "athlete_full_name     3624\n",
      "country_code          1502\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check the columns that contain null value for df_olympic_medals. If the columns with null values are needed later on, then these null values would be processed accordingly.\"\n",
    "null_counts_olympic_medals = df_olympic_medals[[\"discipline_title\", \"slug_game\", \"event_title\", \"event_gender\", \"medal_type\", \"participant_type\", \"participant_title\", \n",
    "                                                \"athlete_url\", \"athlete_full_name\", \"country_name\", \"country_code\", \"country_3_letter_code\"]].isnull().sum()\n",
    "null_columns_olympic_medals = null_counts_olympic_medals[null_counts_olympic_medals > 0]\n",
    "print(null_columns_olympic_medals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# check the columns that contain null value for df_continent. If the columns with null values are needed later on, then these null values would be processed accordingly.\"\n",
    "null_counts_continent = df_continent[[\"country\", \"region\"]].isnull().sum()\n",
    "null_columns_continent = null_counts_continent[null_counts_continent > 0]\n",
    "print(null_columns_continent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# check the columns that contain null value for df_olympic_medals. If the columns with null values are needed later on, then these null values would be processed accordingly.\"\n",
    "null_counts_olympic_hosts = df_olympic_hosts[[\"game_slug\", \"game_end_date\", \"game_start_date\", \"game_location\", \"game_name\", \"game_season\", \"game_year\"]].isnull().sum()\n",
    "null_columns_olympic_hosts = null_counts_olympic_hosts[null_counts_olympic_hosts > 0]\n",
    "print(null_columns_olympic_hosts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code    690\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check the columns that contain null value for df_mental_illness. If the columns with null values are needed later on, then these null values would be processed accordingly.\"\n",
    "null_counts_mental_illness = df_mental_illness[[\"Entity\", \"Code\", \"Year\", \"DALYs from depressive disorders per 100,000 people in, both sexes aged age-standardized\", \n",
    "                                                \"DALYs from schizophrenia per 100,000 people in, both sexes aged age-standardized\", \n",
    "                                                \"DALYs from bipolar disorder per 100,000 people in, both sexes aged age-standardized\", \n",
    "                                                \"DALYs from eating disorders per 100,000 people in, both sexes aged age-standardized\", \n",
    "                                                \"DALYs from anxiety disorders per 100,000 people in, both sexes aged age-standardized\"]].isnull().sum()\n",
    "null_columns_mental_illness = null_counts_mental_illness[null_counts_mental_illness > 0]\n",
    "print(null_columns_mental_illness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## • 2. Tranform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2(1). First Dataframe:\n",
    "#### 2(1-1). For the first dataframe that I need, I obtained it by merging df_olympic_medals, df_olympic_hosts, and df_continent, and preprocessing the data during this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        country_name     slug_game discipline_title  \\\n",
      "0              Italy  beijing-2022          Curling   \n",
      "1              Italy  beijing-2022          Curling   \n",
      "2             Norway  beijing-2022          Curling   \n",
      "3             Norway  beijing-2022          Curling   \n",
      "4             Sweden  beijing-2022          Curling   \n",
      "...              ...           ...              ...   \n",
      "21692        Denmark   athens-1896    Weightlifting   \n",
      "21693         Greece   athens-1896    Weightlifting   \n",
      "21694        Denmark   athens-1896    Weightlifting   \n",
      "21695  Great Britain   athens-1896    Weightlifting   \n",
      "21696         Greece   athens-1896    Weightlifting   \n",
      "\n",
      "                           event_title event_gender medal_type  \\\n",
      "0                        Mixed Doubles        Mixed       GOLD   \n",
      "1                        Mixed Doubles        Mixed       GOLD   \n",
      "2                        Mixed Doubles        Mixed     SILVER   \n",
      "3                        Mixed Doubles        Mixed     SILVER   \n",
      "4                        Mixed Doubles        Mixed     BRONZE   \n",
      "...                                ...          ...        ...   \n",
      "21692  heavyweight - one hand lift men          Men     SILVER   \n",
      "21693  heavyweight - one hand lift men          Men     BRONZE   \n",
      "21694  heavyweight - two hand lift men          Men       GOLD   \n",
      "21695  heavyweight - two hand lift men          Men     SILVER   \n",
      "21696  heavyweight - two hand lift men          Men     BRONZE   \n",
      "\n",
      "      participant_type        athlete_full_name  game_year game_season  \n",
      "0             GameTeam     Stefania CONSTANTINI       2022      Winter  \n",
      "1             GameTeam             Amos MOSANER       2022      Winter  \n",
      "2             GameTeam         Kristin SKASLIEN       2022      Winter  \n",
      "3             GameTeam       Magnus NEDREGOTTEN       2022      Winter  \n",
      "4             GameTeam            Almida DE VAL       2022      Winter  \n",
      "...                ...                      ...        ...         ...  \n",
      "21692          Athlete             Viggo JENSEN       1896      Summer  \n",
      "21693          Athlete  Alexandros Nikolopoulos       1896      Summer  \n",
      "21694          Athlete             Viggo JENSEN       1896      Summer  \n",
      "21695          Athlete        Launceston ELLIOT       1896      Summer  \n",
      "21696          Athlete          Sotirios VERSIS       1896      Summer  \n",
      "\n",
      "[21684 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# Fistly, Merging the df_olympic_medals and df_olympic_hosts dataframes and storing the result in a new dataframe:\n",
    "merged_medals_hosts = pd.merge(df_olympic_medals, df_olympic_hosts, how=\"inner\", left_on=\"slug_game\", right_on=\"game_slug\")\n",
    "\n",
    "''' Since there are some missing values in the athlete_full_name column, so I filled them with \"Unknown\"\n",
    "(I didn't drop the rows because I think it's important to keep the information of other columns):'''\n",
    "merged_medals_hosts[\"athlete_full_name\"] = merged_medals_hosts[\"athlete_full_name\"].fillna(\"Unknown\")\n",
    "\n",
    "''' There are #NAME? in the athlete_full_name column, so I dropped them.\n",
    "(I drop these rows because I checked that the rows with #NAME? are actually have the same information with other rows, \n",
    "so these kind of rows are actually duplicates):'''\n",
    "merged_medals_hosts = merged_medals_hosts[merged_medals_hosts[\"athlete_full_name\"] != \"#NAME?\"]\n",
    "\n",
    "# Reorder the columns and keep only the columns I need:\n",
    "df_merged_medals_hosts = merged_medals_hosts[[\"country_name\", \"slug_game\", \"discipline_title\",\"event_title\", \"event_gender\", \n",
    "                                              \"medal_type\", \"participant_type\", \"athlete_full_name\", \"game_year\", \"game_season\"]]\n",
    "\n",
    "# Print df_merged_data_medals_hosts:\n",
    "print(df_merged_medals_hosts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "''' check the columns that contain null value for df_merged_medals_hosts. \n",
    "If the columns with null values are needed later on, then these null values would be processed accordingly.'''\n",
    "null_counts_merged_medals_hosts = df_merged_medals_hosts[[\"country_name\", \"slug_game\", \"discipline_title\",\"event_title\", \"event_gender\", \"medal_type\", \n",
    "                                                          \"participant_type\", \"athlete_full_name\", \"game_year\", \"game_season\"]].isnull().sum()\n",
    "null_columns_merged_medals_hosts = null_counts_merged_medals_hosts[null_counts_merged_medals_hosts > 0]\n",
    "print(null_columns_merged_medals_hosts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Country Name Continent Game Season     Slug Game Discipline Title  \\\n",
      "0               Italy    Europe      Winter  beijing-2022          Curling   \n",
      "1               Italy    Europe      Winter  beijing-2022          Curling   \n",
      "2              Norway    Europe      Winter  beijing-2022          Curling   \n",
      "3              Norway    Europe      Winter  beijing-2022          Curling   \n",
      "4              Sweden    Europe      Winter  beijing-2022          Curling   \n",
      "...               ...       ...         ...           ...              ...   \n",
      "21679         Denmark    Europe      Summer   athens-1896    Weightlifting   \n",
      "21680          Greece    Europe      Summer   athens-1896    Weightlifting   \n",
      "21681         Denmark    Europe      Summer   athens-1896    Weightlifting   \n",
      "21682  United Kingdom    Europe      Summer   athens-1896    Weightlifting   \n",
      "21683          Greece    Europe      Summer   athens-1896    Weightlifting   \n",
      "\n",
      "      Participant Type Event Gender                      Event Title  \\\n",
      "0             GameTeam        Mixed                    Mixed Doubles   \n",
      "1             GameTeam        Mixed                    Mixed Doubles   \n",
      "2             GameTeam        Mixed                    Mixed Doubles   \n",
      "3             GameTeam        Mixed                    Mixed Doubles   \n",
      "4             GameTeam        Mixed                    Mixed Doubles   \n",
      "...                ...          ...                              ...   \n",
      "21679          Athlete          Men  heavyweight - one hand lift men   \n",
      "21680          Athlete          Men  heavyweight - one hand lift men   \n",
      "21681          Athlete          Men  heavyweight - two hand lift men   \n",
      "21682          Athlete          Men  heavyweight - two hand lift men   \n",
      "21683          Athlete          Men  heavyweight - two hand lift men   \n",
      "\n",
      "       Game Year        Athlete Full Name Medal Type  \n",
      "0           2022     Stefania CONSTANTINI       GOLD  \n",
      "1           2022             Amos MOSANER       GOLD  \n",
      "2           2022         Kristin SKASLIEN     SILVER  \n",
      "3           2022       Magnus NEDREGOTTEN     SILVER  \n",
      "4           2022            Almida DE VAL     BRONZE  \n",
      "...          ...                      ...        ...  \n",
      "21679       1896             Viggo JENSEN     SILVER  \n",
      "21680       1896  Alexandros Nikolopoulos     BRONZE  \n",
      "21681       1896             Viggo JENSEN       GOLD  \n",
      "21682       1896        Launceston ELLIOT     SILVER  \n",
      "21683       1896          Sotirios VERSIS     BRONZE  \n",
      "\n",
      "[21684 rows x 11 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23500/2128643404.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_merged_medals_hosts[\"country_name\"] = df_merged_medals_hosts[\"country_name\"].map(country_name_mapping).fillna(df_merged_medals_hosts[\"country_name\"])\n"
     ]
    }
   ],
   "source": [
    "# After merging the df_olympic_medals and df_olympic_hosts dataframes, I then merged the result with the df_continent dataframe.\n",
    "\n",
    "''' Before merging, I checked the country names in the df_merged_data_medals_hosts dataframe and the country names in the df_continent dataframe, \n",
    "    and found that there are some inconsistent country names, so I created a dictionary to map the old country names to the new country names:'''\n",
    "country_name_mapping = {\n",
    "    \"People's Republic of China\": \"China\",\n",
    "    \"Great Britain\": \"United Kingdom\",\n",
    "    \"United States\": \"United States of America\",\n",
    "    \"Soviet Union\": \"Russia\",\n",
    "    \"Republic of Korea\": \"South Korea\",\n",
    "    \"Democratic People's Republic of Korea\": \"North Korea\",\n",
    "    \"Islamic Republic of\": \"Iran\",\n",
    "    \"Viet Nam\": \"Vietnam\",\n",
    "    \"Czechoslovakia\": \"Czech Republic\",\n",
    "    # Later can add more mappings here\n",
    "}\n",
    "df_merged_medals_hosts[\"country_name\"] = df_merged_medals_hosts[\"country_name\"].map(country_name_mapping).fillna(df_merged_medals_hosts[\"country_name\"])\n",
    "\n",
    "# Merging the df_merged_data_medals_hosts and df_continent dataframes:\n",
    "df_merged_medals_hosts_continent = pd.merge(df_merged_medals_hosts, df_continent, how=\"left\", left_on=\"country_name\", right_on=\"country\")\n",
    "\n",
    "# Keep only the columns I need and rename the columns:\n",
    "df_merged_medals_hosts_continent = df_merged_medals_hosts_continent[[\"country_name\", \"slug_game\", \"discipline_title\", \"event_title\", \"event_gender\", \n",
    "                                                                     \"participant_type\", \"athlete_full_name\", \"medal_type\", \"game_year\", \"game_season\", \"region\"]]\n",
    "df_merged_medals_hosts_continent.columns = [\"Country Name\", \"Slug Game\", \"Discipline Title\", \"Event Title\", \"Event Gender\", \"Participant Type\", \n",
    "                                            \"Athlete Full Name\", \"Medal Type\", \"Game Year\", \"Game Season\", \"Continent\"]\n",
    "\n",
    "# Reorder the columns(I reordered the columns to make every dimension colse to each other):\n",
    "new_order = [\"Country Name\", \"Continent\", \"Game Season\", \"Slug Game\", \"Discipline Title\",\"Participant Type\", \"Event Gender\", \"Event Title\", \n",
    "             \"Game Year\", \"Athlete Full Name\", \"Medal Type\"]\n",
    "df_merged_medals_hosts_continent = df_merged_medals_hosts_continent[new_order]\n",
    "\n",
    "print(df_merged_medals_hosts_continent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continent    5104\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "'''check the columns that contain null value for df_merged_medals_hosts_continet. \n",
    "If the columns with null values are needed later on, then these null values would be processed accordingly.'''\n",
    "null_counts_merged_medals_hosts_continent = df_merged_medals_hosts_continent[[\"Country Name\", \"Continent\", \"Game Season\", \"Slug Game\", \"Discipline Title\",\"Participant Type\", \n",
    "                                                                              \"Event Gender\", \"Event Title\", \"Game Year\", \"Athlete Full Name\", \"Medal Type\"]].isnull().sum()\n",
    "null_columns_merged_medals_hosts_continent = null_counts_merged_medals_hosts_continent[null_counts_merged_medals_hosts_continent > 0]\n",
    "print(null_columns_merged_medals_hosts_continent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Country Name Continent Game Season     Slug Game Discipline Title  \\\n",
      "0               Italy    Europe      Winter  beijing-2022          Curling   \n",
      "1               Italy    Europe      Winter  beijing-2022          Curling   \n",
      "2              Norway    Europe      Winter  beijing-2022          Curling   \n",
      "3              Norway    Europe      Winter  beijing-2022          Curling   \n",
      "4              Sweden    Europe      Winter  beijing-2022          Curling   \n",
      "...               ...       ...         ...           ...              ...   \n",
      "21679         Denmark    Europe      Summer   athens-1896    Weightlifting   \n",
      "21680          Greece    Europe      Summer   athens-1896    Weightlifting   \n",
      "21681         Denmark    Europe      Summer   athens-1896    Weightlifting   \n",
      "21682  United Kingdom    Europe      Summer   athens-1896    Weightlifting   \n",
      "21683          Greece    Europe      Summer   athens-1896    Weightlifting   \n",
      "\n",
      "      Participant Type Event Gender                      Event Title  \\\n",
      "0             GameTeam        Mixed                    Mixed Doubles   \n",
      "1             GameTeam        Mixed                    Mixed Doubles   \n",
      "2             GameTeam        Mixed                    Mixed Doubles   \n",
      "3             GameTeam        Mixed                    Mixed Doubles   \n",
      "4             GameTeam        Mixed                    Mixed Doubles   \n",
      "...                ...          ...                              ...   \n",
      "21679          Athlete          Men  heavyweight - one hand lift men   \n",
      "21680          Athlete          Men  heavyweight - one hand lift men   \n",
      "21681          Athlete          Men  heavyweight - two hand lift men   \n",
      "21682          Athlete          Men  heavyweight - two hand lift men   \n",
      "21683          Athlete          Men  heavyweight - two hand lift men   \n",
      "\n",
      "       Game Year        Athlete Full Name Medal Type  \n",
      "0           2022     Stefania CONSTANTINI       GOLD  \n",
      "1           2022             Amos MOSANER       GOLD  \n",
      "2           2022         Kristin SKASLIEN     SILVER  \n",
      "3           2022       Magnus NEDREGOTTEN     SILVER  \n",
      "4           2022            Almida DE VAL     BRONZE  \n",
      "...          ...                      ...        ...  \n",
      "21679       1896             Viggo JENSEN     SILVER  \n",
      "21680       1896  Alexandros Nikolopoulos     BRONZE  \n",
      "21681       1896             Viggo JENSEN       GOLD  \n",
      "21682       1896        Launceston ELLIOT     SILVER  \n",
      "21683       1896          Sotirios VERSIS     BRONZE  \n",
      "\n",
      "[21680 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "# Fill the missing values in the Continet column with \"Unknown\"(I didn't drop the rows here is because I think the other columns' information is important to keep):\n",
    "df_merged_medals_hosts_continent[\"Continent\"] = df_merged_medals_hosts_continent[\"Continent\"].fillna(\"Unknown\")\n",
    "\n",
    "# Drop the duplicates:\n",
    "df_merged_medals_hosts_continent.drop_duplicates(inplace=True)\n",
    "\n",
    "# Print the final result of my firt dataframe:\n",
    "print(df_merged_medals_hosts_continent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_medals_hosts_continent.to_csv(\"merged_medals_hosts_continent.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2(1-2). Then, I'm going to create six dimension tables and one fact table based on the data/columns in df_merged_medals_hosts_continent dataframe:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - Dimension Tables(six)\n",
    "##### (a). Create Athlete Dimension Table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Athlete ID        Athlete Full Name\n",
      "0               1     Stefania CONSTANTINI\n",
      "1               2             Amos MOSANER\n",
      "2               3         Kristin SKASLIEN\n",
      "3               4       Magnus NEDREGOTTEN\n",
      "4               5            Almida DE VAL\n",
      "...           ...                      ...\n",
      "12883       12884  George Stuart ROBERTSON\n",
      "12884       12885          Georgios TSITAS\n",
      "12885       12886   Stefanos Khristopoulos\n",
      "12886       12887        Launceston ELLIOT\n",
      "12887       12888  Alexandros Nikolopoulos\n",
      "\n",
      "[12888 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Copy the athlete names from the df_merged_medals_hosts_continent dataframe(.copy method is to make sure that the original dataframe is not changed):\n",
    "athlete_names = df_merged_medals_hosts_continent[\"Athlete Full Name\"].copy()\n",
    "\n",
    "# Get unique athlete names(drop duplicates):\n",
    "unique_athletes = athlete_names.unique()\n",
    "\n",
    "# Generate unique athlete IDs starting from 1 for each unique athlete name:\n",
    "athlete_ids = range(1, len(unique_athletes) + 1)\n",
    "\n",
    "# Create a DataFrame containing every unique athlete name and its corresponding athlete ID:\n",
    "df_athlete_dimension = pd.DataFrame({\"Athlete ID\": athlete_ids, \"Athlete Full Name\": unique_athletes})\n",
    "\n",
    "print(df_athlete_dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the df_athlete_dimension dataframe to a csv file:\n",
    "df_athlete_dimension.to_csv(\"athlete_dimension.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (b). Create Medal Type Dimension Table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Medal Type ID Medal Type\n",
      "0              1       GOLD\n",
      "1              2     SILVER\n",
      "2              3     BRONZE\n"
     ]
    }
   ],
   "source": [
    "# copy the country name column frme the df_merged_medals_hosts_continent dataframe(.copy method is to make sure that the original dataframe is not changed):\n",
    "medal_types = df_merged_medals_hosts_continent[\"Medal Type\"]\n",
    "\n",
    "# get the unique medal types(drop duplicates):\n",
    "unique_medal_types = medal_types.unique()\n",
    "\n",
    "# Generate unique medal type IDs starting from 1 for each unique medal type:\n",
    "medal_type_ids = range(1, len(unique_medal_types) + 1)\n",
    "\n",
    "# create a new DataFrame containing the every unique medal type and the corresponding unique ID:\n",
    "df_medal_type_dimension = pd.DataFrame({\"Medal Type ID\": medal_type_ids, \"Medal Type\": unique_medal_types})\n",
    "\n",
    "print(df_medal_type_dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the df_medal_type_dimension dataframe to a csv file:\n",
    "df_medal_type_dimension.to_csv(\"medal_type_dimension.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (c). Create Time Dimension Table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Game Year ID  Game Year\n",
      "0              1       2022\n",
      "1              2       2020\n",
      "2              3       2018\n",
      "3              4       2016\n",
      "4              5       2014\n",
      "5              6       2012\n",
      "6              7       2010\n",
      "7              8       2008\n",
      "8              9       2006\n",
      "9             10       2004\n",
      "10            11       2002\n",
      "11            12       2000\n",
      "12            13       1998\n",
      "13            14       1996\n",
      "14            15       1994\n",
      "15            16       1992\n",
      "16            17       1988\n",
      "17            18       1984\n",
      "18            19       1980\n",
      "19            20       1976\n",
      "20            21       1972\n",
      "21            22       1968\n",
      "22            23       1964\n",
      "23            24       1960\n",
      "24            25       1956\n",
      "25            26       1952\n",
      "26            27       1948\n",
      "27            28       1936\n",
      "28            29       1932\n",
      "29            30       1928\n",
      "30            31       1924\n",
      "31            32       1920\n",
      "32            33       1912\n",
      "33            34       1908\n",
      "34            35       1904\n",
      "35            36       1900\n",
      "36            37       1896\n"
     ]
    }
   ],
   "source": [
    "# copy the game year column from the df_merged_medals_hosts_continent dataframe:\n",
    "game_years = df_merged_medals_hosts_continent[\"Game Year\"].copy()\n",
    "\n",
    "# get the unique game years:\n",
    "unique_game_years = game_years.unique()\n",
    "\n",
    "# generate unique game year IDs starting from 1 for each unique game year:\n",
    "game_year_ids = range(1, len(unique_game_years) + 1)\n",
    "\n",
    "# create a DataFrame containing the game year and the corresponding unique ID\n",
    "df_time_dimension = pd.DataFrame({\"Game Year ID\": game_year_ids, \"Game Year\": unique_game_years})\n",
    "\n",
    "print(df_time_dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the df_time_dimension dataframe to a csv file:\n",
    "df_time_dimension.to_csv(\"time_dimension.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (d). Create Discipline Dimension Table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Discipline Title Participant Type Event Gender  \\\n",
      "Discipline ID                                                   \n",
      "1                       Curling         GameTeam        Mixed   \n",
      "2                       Curling         GameTeam        Women   \n",
      "3                       Curling         GameTeam          Men   \n",
      "4              Freestyle Skiing          Athlete          Men   \n",
      "5              Freestyle Skiing          Athlete          Men   \n",
      "...                         ...              ...          ...   \n",
      "1585                   Shooting          Athlete          Men   \n",
      "1586                   Shooting          Athlete          Men   \n",
      "1587                   Shooting          Athlete          Men   \n",
      "1588                  Wrestling          Athlete          Men   \n",
      "1589              Weightlifting          Athlete          Men   \n",
      "\n",
      "                                    Event Title  \n",
      "Discipline ID                                    \n",
      "1                                 Mixed Doubles  \n",
      "2                                         Women  \n",
      "3                                           Men  \n",
      "4                                  Men's Moguls  \n",
      "5                        Men's Freeski Halfpipe  \n",
      "...                                         ...  \n",
      "1585                        25m army pistol men  \n",
      "1586                        army rifle 200m men  \n",
      "1587                        army rifle 300m men  \n",
      "1588           Unlimited Class, Greco-Roman Men  \n",
      "1589            heavyweight - one hand lift men  \n",
      "\n",
      "[1589 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Copy the discipline title, participant type, Event Gender, and Event Title columns from the df_merged_medals_hosts_continent dataframe:\n",
    "df_discipline_dimension = df_merged_medals_hosts_continent[[\"Discipline Title\", \"Participant Type\", \"Event Gender\",  \"Event Title\"]].copy()\n",
    "\n",
    "# drop duplicates to get unique discipline and event combinations:\n",
    "df_discipline_dimension = df_discipline_dimension.drop_duplicates()\n",
    "\n",
    "# Generate unique IDs starting from 1 for each unique discipline and event combination:\n",
    "df_discipline_dimension[\"Discipline ID\"] = range(1, len(df_discipline_dimension) + 1)\n",
    "\n",
    "# set Disciplin ID as the index of the DataFrame:\n",
    "df_discipline_dimension.set_index(\"Discipline ID\", inplace=True)\n",
    "\n",
    "print(df_discipline_dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the df_discipline_dimension dataframe to a csv file:\n",
    "df_discipline_dimension.to_csv(\"discipline_dimension.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (e). Create Olympic Game Dimension table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Game Season                    Slug Game\n",
      "Olympic Game ID                                         \n",
      "1                    Winter                 beijing-2022\n",
      "2                    Summer                   tokyo-2020\n",
      "3                    Winter             pyeongchang-2018\n",
      "4                    Summer                     rio-2016\n",
      "5                    Winter                   sochi-2014\n",
      "6                    Summer                  london-2012\n",
      "7                    Winter               vancouver-2010\n",
      "8                    Summer                 beijing-2008\n",
      "9                    Winter                   turin-2006\n",
      "10                   Summer                  athens-2004\n",
      "11                   Winter          salt-lake-city-2002\n",
      "12                   Summer                  sydney-2000\n",
      "13                   Winter                  nagano-1998\n",
      "14                   Summer                 atlanta-1996\n",
      "15                   Winter             lillehammer-1994\n",
      "16                   Summer               barcelona-1992\n",
      "17                   Winter             albertville-1992\n",
      "18                   Summer                   seoul-1988\n",
      "19                   Winter                 calgary-1988\n",
      "20                   Summer             los-angeles-1984\n",
      "21                   Winter                sarajevo-1984\n",
      "22                   Summer                  moscow-1980\n",
      "23                   Winter             lake-placid-1980\n",
      "24                   Summer                montreal-1976\n",
      "25                   Winter               innsbruck-1976\n",
      "26                   Summer                  munich-1972\n",
      "27                   Winter                 sapporo-1972\n",
      "28                   Summer             mexico-city-1968\n",
      "29                   Winter                grenoble-1968\n",
      "30                   Summer                   tokyo-1964\n",
      "31                   Winter               innsbruck-1964\n",
      "32                   Summer                    rome-1960\n",
      "33                   Winter            squaw-valley-1960\n",
      "34                   Summer               melbourne-1956\n",
      "35                   Winter       cortina-d-ampezzo-1956\n",
      "36                   Summer                helsinki-1952\n",
      "37                   Winter                    oslo-1952\n",
      "38                   Summer                  london-1948\n",
      "39                   Winter               st-moritz-1948\n",
      "40                   Summer                  berlin-1936\n",
      "41                   Winter  garmisch-partenkirchen-1936\n",
      "42                   Summer             los-angeles-1932\n",
      "43                   Winter             lake-placid-1932\n",
      "44                   Summer               amsterdam-1928\n",
      "45                   Winter               st-moritz-1928\n",
      "46                   Summer                   paris-1924\n",
      "47                   Winter                chamonix-1924\n",
      "48                   Summer                 antwerp-1920\n",
      "49                   Summer               stockholm-1912\n",
      "50                   Summer                  london-1908\n",
      "51                   Summer                st-louis-1904\n",
      "52                   Summer                   paris-1900\n",
      "53                   Summer                  athens-1896\n"
     ]
    }
   ],
   "source": [
    "# Copy Game Season and Slug Game columns from the df_merged_medals_hosts_continent dataframe:\n",
    "df_olympic_game_dimension = df_merged_medals_hosts_continent[[\"Game Season\", \"Slug Game\"]].copy()\n",
    "\n",
    "# drop duplicates to get unique olympic games and seasons combinations:\n",
    "df_olympic_game_dimension = df_olympic_game_dimension.drop_duplicates()\n",
    "\n",
    "# Generate unique IDs starting from 1 for each unique olympic game and season combination:\n",
    "df_olympic_game_dimension[\"Olympic Game ID\"] = range(1, len(df_olympic_game_dimension) + 1)\n",
    "\n",
    "# set Olympic Game ID as the index of df_olympic_game_dimension DataFrame:\n",
    "df_olympic_game_dimension.set_index(\"Olympic Game ID\", inplace=True)\n",
    "\n",
    "print(df_olympic_game_dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the df_olympic_game_dimension dataframe to a csv file:\n",
    "df_olympic_game_dimension.to_csv(\"olympic_game_dimension.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (f). Create Location Dimension Table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Continent    Country Name\n",
      "Location ID                               \n",
      "1                   Europe           Italy\n",
      "2                   Europe          Norway\n",
      "3                   Europe          Sweden\n",
      "4                   Europe  United Kingdom\n",
      "5                     Asia           Japan\n",
      "...                    ...             ...\n",
      "149                   Asia            Iraq\n",
      "150          North America           Haiti\n",
      "151                Unknown     Australasia\n",
      "152                Unknown         Bohemia\n",
      "153                Unknown             MIX\n",
      "\n",
      "[153 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Copy the Country Name and Continent columns from the df_merged_medals_hosts_continent dataframe:\n",
    "df_location_dimension = df_merged_medals_hosts_continent[[\"Continent\", \"Country Name\"]].copy()\n",
    "\n",
    "# drop duplicates to get unique countries and its continents\n",
    "df_location_dimension = df_location_dimension.drop_duplicates()\n",
    "\n",
    "# assign a unique ID to each country and continent combination:\n",
    "df_location_dimension[\"Location ID\"] = range(1, len(df_location_dimension) + 1)\n",
    "\n",
    "# set Location ID as the index of the DataFrame:\n",
    "df_location_dimension.set_index(\"Location ID\", inplace=True)\n",
    "\n",
    "print(df_location_dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the df_location_dimension dataframe to a csv file:\n",
    "df_location_dimension.to_csv(\"location_dimension.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - Fact Table(one)\n",
    "##### (a). Medals Fact Table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Game Year ID  Athlete ID  Medal Type ID  Location ID  Olympic Game ID  \\\n",
      "0                 1           1              1            1                1   \n",
      "1                 1           2              1            1                1   \n",
      "2                 1           3              2            2                1   \n",
      "3                 1           4              2            2                1   \n",
      "4                 1           5              3            3                1   \n",
      "...             ...         ...            ...          ...              ...   \n",
      "21679            37       12877              2           36               53   \n",
      "21680            37       12888              3           69               53   \n",
      "21681            37       12877              1           36               53   \n",
      "21682            37       12887              2            4               53   \n",
      "21683            37       12825              3           69               53   \n",
      "\n",
      "       Discipline ID  \n",
      "0                  1  \n",
      "1                  1  \n",
      "2                  1  \n",
      "3                  1  \n",
      "4                  1  \n",
      "...              ...  \n",
      "21679           1589  \n",
      "21680           1589  \n",
      "21681           1505  \n",
      "21682           1505  \n",
      "21683           1505  \n",
      "\n",
      "[21680 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "''' Here, firstly I'm going to add the unique ID columns for \"Game Year\", \"Athlete Full Name\", and \"Medal Type\", \n",
    "and then also for the combination of [\"Country Name\" and \"Continent\"], [\"Game Season\" and \"Slug Game\"], \n",
    "and [\"Discipline Title\", \"Participant Type\", \"Event Gender\", \"Event Title\"]. '''\n",
    "\n",
    "# Copy the df_merged_medals_hosts_continent dataframe to a new dataframe called df_merged_medals_hosts_continent_add_id_columns:\n",
    "df_merged_medals_hosts_continent_add_id_columns = df_merged_medals_hosts_continent.copy()\n",
    "\n",
    "# Generate unique IDs for \"Game Year\" column starting from 1 for each unique game year:\n",
    "df_merged_medals_hosts_continent_add_id_columns[\"Game Year ID\"] = pd.factorize(df_merged_medals_hosts_continent_add_id_columns[\"Game Year\"])[0] + 1\n",
    "\n",
    "# Generate unique IDs for \"Athlete Full Name\" column starting from 1 for each unique athlete name:\n",
    "df_merged_medals_hosts_continent_add_id_columns[\"Athlete ID\"] = pd.factorize(df_merged_medals_hosts_continent_add_id_columns[\"Athlete Full Name\"])[0] + 1\n",
    "\n",
    "# Generate unique IDs for \"Medal Type\" column starting from 1 for each unique medal type:\n",
    "df_merged_medals_hosts_continent_add_id_columns[\"Medal Type ID\"] = pd.factorize(df_merged_medals_hosts_continent_add_id_columns[\"Medal Type\"])[0] + 1\n",
    "\n",
    "# Generate unique IDs for the combination of \"Country Name\" and \"Continent\" columns starting from 1 for each unique country and continent combination:\n",
    "df_merged_medals_hosts_continent_add_id_columns[\"Location ID\"] = pd.factorize(df_merged_medals_hosts_continent_add_id_columns[\"Country Name\"].astype(str) + \"_\" + \n",
    "                                                                              df_merged_medals_hosts_continent_add_id_columns[\"Continent\"].astype(str))[0] + 1\n",
    "\n",
    "# Generate unique IDs for the combination of \"Game Season\" and \"Slug Game\" columns starting from 1 for each unique slug game and game season combination:\n",
    "df_merged_medals_hosts_continent_add_id_columns[\"Olympic Game ID\"] = pd.factorize(df_merged_medals_hosts_continent_add_id_columns[\"Game Season\"].astype(str) + \"_\" + \n",
    "                                                                                  df_merged_medals_hosts_continent_add_id_columns[\"Slug Game\"].astype(str))[0] + 1\n",
    "\n",
    "''' Generate unique IDs for the combination of \"Discipline Title\", \"Participant Type\", \n",
    "\"Event Gender\", and \"Event Title\" columns starting from 1 for each unique discipline and event combination:'''\n",
    "df_merged_medals_hosts_continent_add_id_columns[\"Discipline ID\"] = pd.factorize(df_merged_medals_hosts_continent_add_id_columns[\"Discipline Title\"].astype(str) + \"_\" + \n",
    "                                                                                df_merged_medals_hosts_continent_add_id_columns[\"Participant Type\"].astype(str) + \"_\" + \n",
    "                                                                                df_merged_medals_hosts_continent_add_id_columns[\"Event Gender\"].astype(str) + \"_\" + \n",
    "                                                                                df_merged_medals_hosts_continent_add_id_columns[\"Event Title\"].astype(str))[0] + 1\n",
    "\n",
    "\n",
    "''' After above steps, now I get a dataframe \"df_merged_medals_hosts_continent_add_id_columns\" which contains \n",
    "    the whole data from the original dataframe \"df_merged_medals_hosts_continent\" \n",
    "    and also the unique ID columns for \"Game Year\", \"Athlete Full Name\", \"Medal Type\", \n",
    "    [\"Country Name\", \"Continent\"], [\"Game Season\", \"Slug Game\"], and [\"Discipline Title\", \"Participant Type\", \"Event Gender\", \"Event Title\"]. '''\n",
    "\n",
    "# Drop the columns that are not needed in the final fact table(only keep the unique ID columns):\n",
    "df_medals_fact = df_merged_medals_hosts_continent_add_id_columns.drop([\"Country Name\", \"Continent\", \"Game Season\", \"Slug Game\", \"Discipline Title\", \"Participant Type\", \n",
    "                                                                       \"Event Gender\", \"Event Title\", \"Game Year\", \"Athlete Full Name\", \"Medal Type\"], axis=1)\n",
    "\n",
    "print(df_medals_fact)\n",
    "\n",
    "# Transform the df_medals_fact dataframe to a csv file, which is the final fact table:\n",
    "df_medals_fact.to_csv(\"medals_fact.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2(2). Second Dataframe:\n",
    "#### 2(2-1). For the second dataframe that I need to use, I obtained it by merging df_olympic_hosts, df_mental_illness, and df_continent, and cleaning and preprocessing the data during this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' firstly, I clean the data in the df_olympic_hosts dataframe by selecting the rows with game_year between 1990 and 2019, \n",
    "    because the data I need to analyze is only from 1990 to 2019(df_mental_illness data is only from 1990 to 2019): '''\n",
    "df_olympic_hosts_1990_2019 = df_olympic_hosts[df_olympic_hosts[\"game_year\"].between(1990, 2019)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Year        Country  DALYs from depressive disorders  \\\n",
      "0    1990      Australia                        799.47360   \n",
      "1    1991      Australia                        805.67530   \n",
      "2    1992      Australia                        811.40607   \n",
      "3    1993      Australia                        816.30450   \n",
      "4    1994      Australia                        820.75977   \n",
      "..    ...            ...                              ...   \n",
      "440  2015  United States                        779.26184   \n",
      "442  2016  United States                        776.84106   \n",
      "444  2017  United States                        775.51465   \n",
      "446  2018  United States                        774.79320   \n",
      "448  2019  United States                        774.97437   \n",
      "\n",
      "     DALYs from schizophrenia  DALYs from bipolar disorder  \\\n",
      "0                   247.54398                    239.77686   \n",
      "1                   247.39116                    239.85439   \n",
      "2                   247.53279                    239.99638   \n",
      "3                   247.43527                    239.99773   \n",
      "4                   247.18256                    240.08994   \n",
      "..                        ...                          ...   \n",
      "440                 277.48273                    128.00395   \n",
      "442                 273.54065                    127.88893   \n",
      "444                 270.42728                    127.74903   \n",
      "446                 270.07968                    127.60620   \n",
      "448                 270.65967                    127.41404   \n",
      "\n",
      "     DALYs from eating disorders  DALYs from anxiety disorders  \\\n",
      "0                     152.447660                     548.39056   \n",
      "1                     153.272230                     539.64105   \n",
      "2                     153.934800                     531.28656   \n",
      "3                     154.773510                     523.87720   \n",
      "4                     155.493240                     517.70010   \n",
      "..                           ...                           ...   \n",
      "440                    88.567820                     487.08698   \n",
      "442                    89.261810                     486.31015   \n",
      "444                    90.058640                     486.70310   \n",
      "446                    89.955910                     501.62817   \n",
      "448                    89.455574                     533.55620   \n",
      "\n",
      "                                             Host Type  \n",
      "0    Non-host Country of the Olympic Games for this...  \n",
      "1    Non-host Country of the Olympic Games for this...  \n",
      "2    Non-host Country of the Olympic Games for this...  \n",
      "3    Non-host Country of the Olympic Games for this...  \n",
      "4    Non-host Country of the Olympic Games for this...  \n",
      "..                                                 ...  \n",
      "440  Non-host Country of the Olympic Games for this...  \n",
      "442  Non-host Country of the Olympic Games for this...  \n",
      "444  Non-host Country of the Olympic Games for this...  \n",
      "446  Non-host Country of the Olympic Games for this...  \n",
      "448  Non-host Country of the Olympic Games for this...  \n",
      "\n",
      "[420 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# After I filtered the df_olympic_hosts dataframe, I then merged the df_olympic_hosts_1990_2019 and df_continent dataframes by this part of the code:\n",
    "\n",
    "# mapping the inconsistent country names to keep the country names consistent between the two dataframes:\n",
    "country_mapping = {\n",
    "    \"South Korea\": \"Republic of Korea\",\n",
    "    \"United Kingdom\": \"Great Britain\",\n",
    "    \"Russia\": \"Russian Federation\",\n",
    "    # Add more mappings as needed\n",
    "}\n",
    "df_mental_illness[\"Entity\"] = df_mental_illness[\"Entity\"].map(country_mapping).fillna(df_mental_illness[\"Entity\"])\n",
    "\n",
    "# Merge the df_mental_illness and df_olympic_hosts_1990_2019 dataframes:\n",
    "df_host_country_mental_illness_DALYs = pd.merge(df_mental_illness, df_olympic_hosts_1990_2019, how=\"inner\", left_on=\"Entity\", right_on=\"game_location\")\n",
    "\n",
    "# Filter out entities not present in game_location, because the data I need to analyse is only for the host countries(game location) of the Olympic Games:\n",
    "df_host_country_mental_illness_DALYs = df_host_country_mental_illness_DALYs[df_host_country_mental_illness_DALYs[\"Entity\"].isin(df_olympic_hosts[\"game_location\"])]\n",
    "\n",
    "# Reorder columns and keep only the columns I need:\n",
    "df_host_country_mental_illness_DALYs = df_host_country_mental_illness_DALYs[[\"Year\", \"Entity\", \n",
    "                           \"DALYs from depressive disorders per 100,000 people in, both sexes aged age-standardized\",\n",
    "                           \"DALYs from schizophrenia per 100,000 people in, both sexes aged age-standardized\",\n",
    "                           \"DALYs from bipolar disorder per 100,000 people in, both sexes aged age-standardized\",\n",
    "                           \"DALYs from eating disorders per 100,000 people in, both sexes aged age-standardized\",\n",
    "                           \"DALYs from anxiety disorders per 100,000 people in, both sexes aged age-standardized\",\n",
    "                           \"game_year\"]]\n",
    "\n",
    "# Define a function to map the game_year column, based on the Year and game_year columns to determine if the country is the host country of the Olympic Games for this year:\n",
    "def map_game_year(row):\n",
    "    if row[\"Year\"] == row[\"game_year\"]:\n",
    "        return \"Host Country of the Olympic Games for this year\"\n",
    "    else:\n",
    "        return \"Non-host Country of the Olympic Games for this year\"\n",
    "\n",
    "# Apply the above function to create the game_year column:\n",
    "df_host_country_mental_illness_DALYs[\"game_year\"] = df_host_country_mental_illness_DALYs.apply(map_game_year, axis=1)\n",
    "\n",
    "# Rename columns, change \"Entity\" to \"Country\", and \"game_year\" to \"Host Type\":\n",
    "df_host_country_mental_illness_DALYs.columns = [\"Year\", \"Country\", \"DALYs from depressive disorders\", \n",
    "                       \"DALYs from schizophrenia\", \"DALYs from bipolar disorder\", \n",
    "                       \"DALYs from eating disorders\", \"DALYs from anxiety disorders\", \"Host Type\"]\n",
    "\n",
    "# Delete duplicates rows based on the condition(for those contries that have been host more than one once):\n",
    "df_host_country_mental_illness_DALYs.drop_duplicates(inplace=True)\n",
    "condition = ((df_host_country_mental_illness_DALYs[\"Host Type\"] == \"Non-host Country of the Olympic Games for this year\") &\n",
    "             (df_host_country_mental_illness_DALYs.duplicated(subset=[\"Year\", \"DALYs from depressive disorders\", \"DALYs from schizophrenia\", \n",
    "                                       \"DALYs from bipolar disorder\", \"DALYs from eating disorders\", \n",
    "                                       \"DALYs from anxiety disorders\"], keep=False)))\n",
    "df_host_country_mental_illness_DALYs = df_host_country_mental_illness_DALYs[~condition]\n",
    "\n",
    "print(df_host_country_mental_illness_DALYs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Year        Country      Continent  DALYs from depressive disorders  \\\n",
      "0    1990      Australia        Oceania                        799.47360   \n",
      "1    1991      Australia        Oceania                        805.67530   \n",
      "2    1992      Australia        Oceania                        811.40607   \n",
      "3    1993      Australia        Oceania                        816.30450   \n",
      "4    1994      Australia        Oceania                        820.75977   \n",
      "..    ...            ...            ...                              ...   \n",
      "440  2015  United States  North America                        779.26184   \n",
      "442  2016  United States  North America                        776.84106   \n",
      "444  2017  United States  North America                        775.51465   \n",
      "446  2018  United States  North America                        774.79320   \n",
      "448  2019  United States  North America                        774.97437   \n",
      "\n",
      "     DALYs from schizophrenia  DALYs from bipolar disorder  \\\n",
      "0                   247.54398                    239.77686   \n",
      "1                   247.39116                    239.85439   \n",
      "2                   247.53279                    239.99638   \n",
      "3                   247.43527                    239.99773   \n",
      "4                   247.18256                    240.08994   \n",
      "..                        ...                          ...   \n",
      "440                 277.48273                    128.00395   \n",
      "442                 273.54065                    127.88893   \n",
      "444                 270.42728                    127.74903   \n",
      "446                 270.07968                    127.60620   \n",
      "448                 270.65967                    127.41404   \n",
      "\n",
      "     DALYs from eating disorders  DALYs from anxiety disorders  \\\n",
      "0                     152.447660                     548.39056   \n",
      "1                     153.272230                     539.64105   \n",
      "2                     153.934800                     531.28656   \n",
      "3                     154.773510                     523.87720   \n",
      "4                     155.493240                     517.70010   \n",
      "..                           ...                           ...   \n",
      "440                    88.567820                     487.08698   \n",
      "442                    89.261810                     486.31015   \n",
      "444                    90.058640                     486.70310   \n",
      "446                    89.955910                     501.62817   \n",
      "448                    89.455574                     533.55620   \n",
      "\n",
      "                                             Host Type  \n",
      "0    Non-host Country of the Olympic Games for this...  \n",
      "1    Non-host Country of the Olympic Games for this...  \n",
      "2    Non-host Country of the Olympic Games for this...  \n",
      "3    Non-host Country of the Olympic Games for this...  \n",
      "4    Non-host Country of the Olympic Games for this...  \n",
      "..                                                 ...  \n",
      "440  Non-host Country of the Olympic Games for this...  \n",
      "442  Non-host Country of the Olympic Games for this...  \n",
      "444  Non-host Country of the Olympic Games for this...  \n",
      "446  Non-host Country of the Olympic Games for this...  \n",
      "448  Non-host Country of the Olympic Games for this...  \n",
      "\n",
      "[420 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "''' I got the dataframe that merges the df_mental_illness and df_olympic_hosts_1990_2019 dataframes, \n",
    "then I need to add the continent information to the df_host_country_mental_illness_DALYs dataframe: '''\n",
    "\n",
    "# mapping the inconsistent country names to keep the country names consistent between the two dataframes:\n",
    "country_mapping = {\n",
    "    \"Republic of Korea\": \"South Korea\",\n",
    "    \"Russian Federation\": \"Russia\",\n",
    "    \"Great Britain\": \"United Kingdom\",\n",
    "    # Add more mappings as needed\n",
    "}\n",
    "df_host_country_mental_illness_DALYs[\"Country\"] = df_host_country_mental_illness_DALYs[\"Country\"].replace(country_mapping)\n",
    "\n",
    "# Add the continent information to the df_host_country_mental_illness_DALYs dataframe:\n",
    "df_host_country_mental_illness_DALYs[\"Continent\"] = df_host_country_mental_illness_DALYs[\"Country\"].map(df_continent.set_index(\"country\")[\"region\"])\n",
    "df_host_country_mental_illness_DALYs.insert(2, \"Continent\", df_host_country_mental_illness_DALYs.pop(\"Continent\")) # Moving the 'Continent\" column to the 3rd column\n",
    "\n",
    "# \n",
    "print(df_host_country_mental_illness_DALYs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "''' check the columns that contain null value for df_host_country_mental_illness_DALYs. \n",
    "If the columns with null values are needed later on, then these null values would be processed accordingly.'''\n",
    "null_counts_host_country_mental_illness_DALYs = df_host_country_mental_illness_DALYs[[\"Year\",\"Country\", \"Continent\", \"DALYs from depressive disorders\", \n",
    "                                                                                      \"DALYs from schizophrenia\", \"DALYs from bipolar disorder\", \"DALYs from eating disorders\", \n",
    "                                                                                      \"DALYs from anxiety disorders\"]].isnull().sum()\n",
    "null_columns_host_country_mental_illness_DALYs = null_counts_host_country_mental_illness_DALYs[null_counts_host_country_mental_illness_DALYs > 0]\n",
    "print(null_columns_host_country_mental_illness_DALYs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2(2-2). Then, I'm going to create dimension tables and fact table based on df_host_country_mental_illness_DALYs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - Dimension Tables(three)\n",
    "##### (a). Year Dimension Table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Year ID  Year\n",
      "0         1  1990\n",
      "1         2  1991\n",
      "2         3  1992\n",
      "3         4  1993\n",
      "4         5  1994\n",
      "5         6  1995\n",
      "6         7  1996\n",
      "7         8  1997\n",
      "8         9  1998\n",
      "9        10  1999\n",
      "10       11  2000\n",
      "11       12  2001\n",
      "12       13  2002\n",
      "13       14  2003\n",
      "14       15  2004\n",
      "15       16  2005\n",
      "16       17  2006\n",
      "17       18  2007\n",
      "18       19  2008\n",
      "19       20  2009\n",
      "20       21  2010\n",
      "21       22  2011\n",
      "22       23  2012\n",
      "23       24  2013\n",
      "24       25  2014\n",
      "25       26  2015\n",
      "26       27  2016\n",
      "27       28  2017\n",
      "28       29  2018\n",
      "29       30  2019\n"
     ]
    }
   ],
   "source": [
    "# copy the \"Year\" column from the df_host_country_mental_illness_DALYs dataframe:\n",
    "year = df_host_country_mental_illness_DALYs[\"Year\"].copy()\n",
    "\n",
    "# get the unique years(drop duplicates):\n",
    "unique_years = year.unique()\n",
    "\n",
    "# Generate unique year IDs starting from 1 for each unique year:\n",
    "year_ids = range(1, len(unique_years) + 1)\n",
    "\n",
    "# create a new DataFrame containing the year and the corresponding unique ID:\n",
    "df_year_dimension = pd.DataFrame({\"Year ID\": year_ids, \"Year\": unique_years})\n",
    "\n",
    "# print the result\n",
    "print(df_year_dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the df_year_dimension dataframe to a csv file:\n",
    "df_year_dimension.to_csv(\"year_dimension.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b). Mental Illness Location Dimension Table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                Continent         Country\n",
      "Mental Illness Location ID                               \n",
      "1                                 Oceania       Australia\n",
      "2                           South America          Brazil\n",
      "3                           North America          Canada\n",
      "4                                    Asia           China\n",
      "5                                  Europe          France\n",
      "6                                  Europe          Greece\n",
      "7                                  Europe           Italy\n",
      "8                                    Asia           Japan\n",
      "9                                  Europe          Norway\n",
      "10                                 Europe          Russia\n",
      "11                                   Asia     South Korea\n",
      "12                                 Europe           Spain\n",
      "13                                 Europe  United Kingdom\n",
      "14                          North America   United States\n"
     ]
    }
   ],
   "source": [
    "# copy the \"Continent\" and \"Country\" columns from the df_host_country_mental_illness_DALYs dataframe:\n",
    "df_mental_illness_location_dimension = df_host_country_mental_illness_DALYs[[\"Continent\", \"Country\"]].copy()\n",
    "\n",
    "# drop duplicates to get unique countries and its continents:\n",
    "df_mental_illness_location_dimension = df_mental_illness_location_dimension.drop_duplicates()\n",
    "\n",
    "# Generate unique IDs starting from 1 for each unique country and continent combination:\n",
    "df_mental_illness_location_dimension[\"Mental Illness Location ID\"] = range(1, len(df_mental_illness_location_dimension) + 1)\n",
    "\n",
    "# set the \"Mental Illness Location ID\" as the index of df_mental_illness_location_dimension DataFrame:\n",
    "df_mental_illness_location_dimension.set_index(\"Mental Illness Location ID\", inplace=True)\n",
    "\n",
    "print(df_mental_illness_location_dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the df_mental_illness_location_dimension dataframe to a csv file:\n",
    "df_mental_illness_location_dimension.to_csv(\"mental_illness_location_dimension.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (c). Host Type Dimension Table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Host Type ID                                          Host Type\n",
      "0             1  Non-host Country of the Olympic Games for this...\n",
      "1             2    Host Country of the Olympic Games for this year\n"
     ]
    }
   ],
   "source": [
    "# Copy the \"Host Type\" column from the df_host_country_mental_illness_DALYs dataframe:\n",
    "host_type = df_host_country_mental_illness_DALYs[\"Host Type\"].copy()\n",
    "\n",
    "# get the unique host types(drop duplicates):\n",
    "unique_host_type = host_type.unique()\n",
    "\n",
    "# Generate unique host type IDs starting from 1 for each unique host type:\n",
    "host_type_ids = range(1, len(unique_host_type) + 1)\n",
    "\n",
    "# create a new DataFrame containing the host type and the corresponding unique ID:\n",
    "df_host_type_dimension = pd.DataFrame({\"Host Type ID\": host_type_ids, \"Host Type\": unique_host_type})\n",
    "\n",
    "print(df_host_type_dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the df_host_type_dimension dataframe to a csv file:\n",
    "df_host_type_dimension.to_csv(\"host_type_dimension.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - Fact Table(one)\n",
    "##### (a). Mental Illness DALYs Fact Table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Year ID  Mental Illness Location ID  Host Type ID  \\\n",
      "0          1                           1             1   \n",
      "1          2                           1             1   \n",
      "2          3                           1             1   \n",
      "3          4                           1             1   \n",
      "4          5                           1             1   \n",
      "..       ...                         ...           ...   \n",
      "440       26                          14             1   \n",
      "442       27                          14             1   \n",
      "444       28                          14             1   \n",
      "446       29                          14             1   \n",
      "448       30                          14             1   \n",
      "\n",
      "     DALYs from depressive disorders  DALYs from schizophrenia  \\\n",
      "0                          799.47360                 247.54398   \n",
      "1                          805.67530                 247.39116   \n",
      "2                          811.40607                 247.53279   \n",
      "3                          816.30450                 247.43527   \n",
      "4                          820.75977                 247.18256   \n",
      "..                               ...                       ...   \n",
      "440                        779.26184                 277.48273   \n",
      "442                        776.84106                 273.54065   \n",
      "444                        775.51465                 270.42728   \n",
      "446                        774.79320                 270.07968   \n",
      "448                        774.97437                 270.65967   \n",
      "\n",
      "     DALYs from bipolar disorder  DALYs from eating disorders  \\\n",
      "0                      239.77686                   152.447660   \n",
      "1                      239.85439                   153.272230   \n",
      "2                      239.99638                   153.934800   \n",
      "3                      239.99773                   154.773510   \n",
      "4                      240.08994                   155.493240   \n",
      "..                           ...                          ...   \n",
      "440                    128.00395                    88.567820   \n",
      "442                    127.88893                    89.261810   \n",
      "444                    127.74903                    90.058640   \n",
      "446                    127.60620                    89.955910   \n",
      "448                    127.41404                    89.455574   \n",
      "\n",
      "     DALYs from anxiety disorders  \n",
      "0                       548.39056  \n",
      "1                       539.64105  \n",
      "2                       531.28656  \n",
      "3                       523.87720  \n",
      "4                       517.70010  \n",
      "..                            ...  \n",
      "440                     487.08698  \n",
      "442                     486.31015  \n",
      "444                     486.70310  \n",
      "446                     501.62817  \n",
      "448                     533.55620  \n",
      "\n",
      "[420 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "''' Here, firstly I'm going to add the unique ID columns for \"Year\" and \"Host Type\", \n",
    "and also for the combination of [\"Country\" and \"Continent\"] to the df_host_country_mental_illness_DALYs dataframe. '''\n",
    "\n",
    "# Copy the df_host_country_mental_illness_DALYs dataframe to a new dataframe called df_host_country_mental_illness_DALYs_add_id_columns:\n",
    "df_host_country_mental_illness_DALYs_add_id_columns = df_host_country_mental_illness_DALYs.copy()\n",
    "\n",
    "# Generate unique IDs for \"Year\" column starting from 1 for each unique year:\n",
    "df_host_country_mental_illness_DALYs_add_id_columns[\"Year ID\"] = pd.factorize(df_host_country_mental_illness_DALYs_add_id_columns[\"Year\"])[0] + 1\n",
    "\n",
    "# Generate unique IDs for the combination of \"Country\" and \"Continent\" columns starting from 1 for each unique country and continent combination:\n",
    "df_host_country_mental_illness_DALYs_add_id_columns[\"Mental Illness Location ID\"] = pd.factorize(df_host_country_mental_illness_DALYs_add_id_columns[\"Country\"].astype(str) \n",
    "                                                                                                 + \"_\" + df_host_country_mental_illness_DALYs_add_id_columns[\"Continent\"].astype(str))[0] + 1\n",
    "\n",
    "# Generate unique IDs for \"Host Type\" column starting from 1 for each unique host type:\n",
    "df_host_country_mental_illness_DALYs_add_id_columns[\"Host Type ID\"] = pd.factorize(df_host_country_mental_illness_DALYs_add_id_columns[\"Host Type\"])[0] + 1\n",
    "\n",
    "''' After above steps, now I get a dataframe \"df_host_country_mental_illness_DALYs_add_id_columns\" which contains\n",
    "    the whole data from the original dataframe \"df_host_country_mental_illness_DALYs\"\n",
    "    and also the unique ID columns for \"Year\", [\"Country\", \"Continent\"], and \"Host Type\". '''\n",
    "\n",
    "# Drop the columns that are not needed in the final fact table(only keep the unique ID columns):\n",
    "df_mental_illness_DALYs_fact = df_host_country_mental_illness_DALYs_add_id_columns.drop([\"Year\", \"Country\", \"Continent\", \"Host Type\"], axis=1)\n",
    "\n",
    "# Reorder the columns:\n",
    "df_mental_illness_DALYs_fact = df_mental_illness_DALYs_fact[[\"Year ID\", \"Mental Illness Location ID\", \"Host Type ID\", \"DALYs from depressive disorders\", \n",
    "                                                             \"DALYs from schizophrenia\", \"DALYs from bipolar disorder\", \"DALYs from eating disorders\", \n",
    "                                                             \"DALYs from anxiety disorders\"]]\n",
    "\n",
    "print(df_mental_illness_DALYs_fact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the df_mental_illness_DALYs_fact dataframe to a csv file, which is the final fact table:\n",
    "df_mental_illness_DALYs_fact.to_csv(\"mental_illness_DALYs_fact.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## • 3. Load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3(1). Dump data into tables in PostgreSQL database:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3(1-1). \"Olympic_Medals_Count\" PostgreSQL database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a database connection engine to connect the \"Olympic_Medals_Count\" PostgreSQL database:\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine(\"postgresql://postgres:postgres@pgdb:5432/Olympic_Medals_Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "888"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dump the data in df_athlete_dimension to \"Olympic_Medals_Count\" PostgreSQL database:\n",
    "df_athlete_dimension.to_sql(\"dim_athlete\", con = engine, if_exists = \"append\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dump the data in df_medal_type_dimension to \"Olympic_Medals_Count\" PostgreSQL database:\n",
    "df_medal_type_dimension.to_sql(\"dim_medal_types\", con = engine, if_exists = \"append\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dump the data in df_time_dimension to \"Olympic_Medals_Count\" PostgreSQL database:\n",
    "df_time_dimension.to_sql(\"dim_time\", con = engine, if_exists = \"append\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "589"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dump the data in df_discipline_dimension to \"Olympic_Medals_Count\" PostgreSQL database:\n",
    "df_discipline_dimension.to_sql(\"dim_discipline\", con = engine, if_exists = \"append\", index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dump the data in df_olympic_game_dimension to \"Olympic_Medals_Count\" PostgreSQL database:\n",
    "df_olympic_game_dimension.to_sql(\"dim_olympic_game\", con = engine, if_exists = \"append\", index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dump the data in df_location_dimension to \"Olympic_Medals_Count\" PostgreSQL database:\n",
    "df_location_dimension.to_sql(\"dim_location\", con = engine, if_exists = \"append\", index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "680"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dump the data in df_medals_fact to \"Olympic_Medals_Count\" PostgreSQL database:\n",
    "df_medals_fact.to_sql(\"fact_medals_count\", con = engine, if_exists = \"append\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3(2-1). \"Mental_Illness_DALYs\" PostgreSQL database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a database connection engine to connect the \"Mental_Illness_DALYs\" PostgreSQL database:\n",
    "engine = create_engine(\"postgresql://postgres:postgres@pgdb:5432/Mental_Illness_DALYs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dump the data in df_year_dimension to \"Mental_Illness_DALYs\" PostgreSQL database:\n",
    "df_year_dimension.to_sql(\"dim_year\", con = engine, if_exists = \"append\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dump the data in df_mental_illness_location_dimension to \"Mental_Illness_DALYs\" PostgreSQL database:\n",
    "df_mental_illness_location_dimension.to_sql(\"dim_mental_illness_location\", con = engine, if_exists = \"append\", index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dump the data in df_host_type_dimension to \"Mental_Illness_DALYs\" PostgreSQL database:\n",
    "df_host_type_dimension.to_sql(\"dim_host_types\", con = engine, if_exists = \"append\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "420"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dump the data df_mental_illness_DALYs_fact to \"Mental_Illness_DALYs\" PostgreSQL database:\n",
    "df_mental_illness_DALYs_fact.to_sql(\"fact_mental_illness_dalys\", con = engine, if_exists = \"append\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
